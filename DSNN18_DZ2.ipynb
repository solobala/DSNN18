{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "l4VAzKlG8aHj"
   },
   "source": [
    "## Neural Part Of Speech Tagging\n",
    "\n",
    "We're now going to solve the same problem of POS tagging with neural networks.\n",
    "<img src=https://i.stack.imgur.com/6pdIT.png width=320>\n",
    "\n",
    "From deep learning perspective, this is a task of predicting a sequence of outputs aligned to a sequence of inputs. There are several problems that match this formulation:\n",
    "* Part Of Speech Tagging -  an auxuliary task for many NLP problems\n",
    "* Named Entity Recognition - for chat bots and web crawlers\n",
    "* Protein structure prediction - for bioinformatics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
    "import nltk\n",
    "import sys\n",
    "import numpy as np\n",
    "import os, datetime\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.layers import CRF\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_19284/2680082382.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "# The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University.\n",
    "nltk.download('universal_tagset')\n",
    "\"\"\"\n",
    "'universal_tagset' - это набор тэгов для частей речи из 12 позиций\n",
    "VERB - verbs (all tenses and modes)\n",
    "NOUN - nouns (common and proper)\n",
    "PRON - pronouns \n",
    "ADJ - adjectives\n",
    "ADV - adverbs\n",
    "ADP - adpositions (prepositions and postpositions)\n",
    "CONJ - conjunctions\n",
    "DET - determiners\n",
    "NUM - cardinal numbers\n",
    "PRT - particles or other function words\n",
    "X - other: foreign words, typos, abbreviations\n",
    ". - punctuation\n",
    "\"\"\"\n",
    "# Теперь каждому слову из предложеий data ставим в соответствие тэг\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
    "# и переводим все  внижний регистр\n",
    "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Bq_OXuD38aHs"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем каталог для хранения логов\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"rm\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "# Удаляем старые логи\n",
    "!rm -rf f'{log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sAlXrDmU8aHs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw(sentence):\n",
    "    \"\"\"\n",
    "    Выводит часть речи над каждым словом в предложении\n",
    "    \"\"\"\n",
    "    words,tags = zip(*sentence)\n",
    "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
    "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
    "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
    "    \n",
    "    \n",
    "draw(data[11])\n",
    "draw(data[10])\n",
    "draw(data[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAViiL2C8aHt"
   },
   "source": [
    "### Создание словарей\n",
    "\n",
    "Как и раньше, нам нужно построить отображение токенов на целочисленные идентификаторы. На этот раз наша модель работает на уровне слов, обрабатывая одно слово за шаг RNN. Это означает, что нам придется иметь дело с гораздо большим словарным запасом.\n",
    "\n",
    "К счастью для нас, мы получаем эти слова только в качестве входных данных, то есть нам не нужно их предсказывать. Это означает, что мы можем иметь большой словарный запас бесплатно, используя встраивание слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZXK_k-mo8aHt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage = 0.92876\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words,tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "# Добавим  втеги еще 2 - '#EOS#' для редко используемых слов и #UNK# для незнакомых и обрежем к-во ключей в словаре до 10000\n",
    "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
    "\n",
    "# давайте измерим, какая часть слов данных находится в словаре\n",
    "print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "T0hee8L88aHt"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Класс defaultdict() модуля collections ничем не отличается от обычного словаря за исключением того, \n",
    "что по умолчанию всегда вызывается функция, которая возвращает значение по умолчанию для новых значений. \n",
    "Другими словами Класс defaultdict() представляет собой словарь со значениями по умолчанию\n",
    "\"\"\"\n",
    "word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) })\n",
    "tag_to_id = { tag: i for i, tag in enumerate(all_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#EOS#': 0,\n",
       " '#UNK#': 1,\n",
       " 'ADV': 2,\n",
       " 'NOUN': 3,\n",
       " 'ADP': 4,\n",
       " 'PRON': 5,\n",
       " 'DET': 6,\n",
       " '.': 7,\n",
       " 'PRT': 8,\n",
       " 'VERB': 9,\n",
       " 'X': 10,\n",
       " 'NUM': 11,\n",
       " 'CONJ': 12,\n",
       " 'ADJ': 13}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_id # Это словарь тэгов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'#EOS#': 0,\n",
       "             '#UNK#': 1,\n",
       "             'the': 2,\n",
       "             ',': 3,\n",
       "             '.': 4,\n",
       "             'of': 5,\n",
       "             'and': 6,\n",
       "             'to': 7,\n",
       "             'a': 8,\n",
       "             'in': 9,\n",
       "             'that': 10,\n",
       "             'is': 11,\n",
       "             'was': 12,\n",
       "             'he': 13,\n",
       "             'for': 14,\n",
       "             '``': 15,\n",
       "             \"''\": 16,\n",
       "             'it': 17,\n",
       "             'with': 18,\n",
       "             'as': 19,\n",
       "             'his': 20,\n",
       "             'on': 21,\n",
       "             'be': 22,\n",
       "             ';': 23,\n",
       "             'at': 24,\n",
       "             'by': 25,\n",
       "             'i': 26,\n",
       "             'this': 27,\n",
       "             'had': 28,\n",
       "             '?': 29,\n",
       "             'not': 30,\n",
       "             'are': 31,\n",
       "             'but': 32,\n",
       "             'from': 33,\n",
       "             'or': 34,\n",
       "             'have': 35,\n",
       "             'an': 36,\n",
       "             'they': 37,\n",
       "             'which': 38,\n",
       "             '--': 39,\n",
       "             'one': 40,\n",
       "             'you': 41,\n",
       "             'were': 42,\n",
       "             'her': 43,\n",
       "             'all': 44,\n",
       "             'she': 45,\n",
       "             'there': 46,\n",
       "             'would': 47,\n",
       "             'their': 48,\n",
       "             'we': 49,\n",
       "             'him': 50,\n",
       "             'been': 51,\n",
       "             ')': 52,\n",
       "             'has': 53,\n",
       "             '(': 54,\n",
       "             'when': 55,\n",
       "             'who': 56,\n",
       "             'will': 57,\n",
       "             'more': 58,\n",
       "             'if': 59,\n",
       "             'no': 60,\n",
       "             'out': 61,\n",
       "             'so': 62,\n",
       "             'said': 63,\n",
       "             'what': 64,\n",
       "             'up': 65,\n",
       "             'its': 66,\n",
       "             'about': 67,\n",
       "             ':': 68,\n",
       "             'into': 69,\n",
       "             'than': 70,\n",
       "             'them': 71,\n",
       "             'can': 72,\n",
       "             'only': 73,\n",
       "             'other': 74,\n",
       "             'new': 75,\n",
       "             'some': 76,\n",
       "             'could': 77,\n",
       "             'time': 78,\n",
       "             '!': 79,\n",
       "             'these': 80,\n",
       "             'two': 81,\n",
       "             'may': 82,\n",
       "             'then': 83,\n",
       "             'do': 84,\n",
       "             'first': 85,\n",
       "             'any': 86,\n",
       "             'my': 87,\n",
       "             'now': 88,\n",
       "             'such': 89,\n",
       "             'like': 90,\n",
       "             'our': 91,\n",
       "             'over': 92,\n",
       "             'man': 93,\n",
       "             'me': 94,\n",
       "             'even': 95,\n",
       "             'most': 96,\n",
       "             'made': 97,\n",
       "             'also': 98,\n",
       "             'after': 99,\n",
       "             'did': 100,\n",
       "             'many': 101,\n",
       "             'before': 102,\n",
       "             'must': 103,\n",
       "             'af': 104,\n",
       "             'through': 105,\n",
       "             'back': 106,\n",
       "             'years': 107,\n",
       "             'where': 108,\n",
       "             'much': 109,\n",
       "             'your': 110,\n",
       "             'way': 111,\n",
       "             'well': 112,\n",
       "             'down': 113,\n",
       "             'should': 114,\n",
       "             'because': 115,\n",
       "             'each': 116,\n",
       "             'just': 117,\n",
       "             'those': 118,\n",
       "             'people': 119,\n",
       "             'mr.': 120,\n",
       "             'too': 121,\n",
       "             'how': 122,\n",
       "             'little': 123,\n",
       "             'state': 124,\n",
       "             'good': 125,\n",
       "             'very': 126,\n",
       "             'make': 127,\n",
       "             'world': 128,\n",
       "             'still': 129,\n",
       "             'see': 130,\n",
       "             'own': 131,\n",
       "             'men': 132,\n",
       "             'work': 133,\n",
       "             'long': 134,\n",
       "             'here': 135,\n",
       "             'get': 136,\n",
       "             'both': 137,\n",
       "             'between': 138,\n",
       "             'life': 139,\n",
       "             'being': 140,\n",
       "             'under': 141,\n",
       "             'never': 142,\n",
       "             'day': 143,\n",
       "             'same': 144,\n",
       "             'another': 145,\n",
       "             'know': 146,\n",
       "             'while': 147,\n",
       "             'last': 148,\n",
       "             'us': 149,\n",
       "             'might': 150,\n",
       "             'great': 151,\n",
       "             'old': 152,\n",
       "             'year': 153,\n",
       "             'off': 154,\n",
       "             'come': 155,\n",
       "             'since': 156,\n",
       "             'against': 157,\n",
       "             'go': 158,\n",
       "             'came': 159,\n",
       "             'right': 160,\n",
       "             'used': 161,\n",
       "             'take': 162,\n",
       "             'three': 163,\n",
       "             'himself': 164,\n",
       "             'states': 165,\n",
       "             'few': 166,\n",
       "             'house': 167,\n",
       "             'use': 168,\n",
       "             'during': 169,\n",
       "             'without': 170,\n",
       "             'again': 171,\n",
       "             'place': 172,\n",
       "             'american': 173,\n",
       "             'around': 174,\n",
       "             'however': 175,\n",
       "             'home': 176,\n",
       "             'small': 177,\n",
       "             'found': 178,\n",
       "             'mrs.': 179,\n",
       "             '1': 180,\n",
       "             'thought': 181,\n",
       "             'went': 182,\n",
       "             'say': 183,\n",
       "             'part': 184,\n",
       "             'once': 185,\n",
       "             'general': 186,\n",
       "             'high': 187,\n",
       "             'upon': 188,\n",
       "             'school': 189,\n",
       "             'every': 190,\n",
       "             \"don't\": 191,\n",
       "             'does': 192,\n",
       "             'got': 193,\n",
       "             'united': 194,\n",
       "             'left': 195,\n",
       "             'number': 196,\n",
       "             'course': 197,\n",
       "             'war': 198,\n",
       "             'until': 199,\n",
       "             'always': 200,\n",
       "             'away': 201,\n",
       "             'something': 202,\n",
       "             'fact': 203,\n",
       "             '2': 204,\n",
       "             'water': 205,\n",
       "             'though': 206,\n",
       "             'public': 207,\n",
       "             'less': 208,\n",
       "             'put': 209,\n",
       "             'think': 210,\n",
       "             'almost': 211,\n",
       "             'hand': 212,\n",
       "             'enough': 213,\n",
       "             'took': 214,\n",
       "             'far': 215,\n",
       "             'head': 216,\n",
       "             'yet': 217,\n",
       "             'government': 218,\n",
       "             'system': 219,\n",
       "             'set': 220,\n",
       "             'better': 221,\n",
       "             'told': 222,\n",
       "             'night': 223,\n",
       "             'nothing': 224,\n",
       "             'end': 225,\n",
       "             'why': 226,\n",
       "             \"didn't\": 227,\n",
       "             'called': 228,\n",
       "             'eyes': 229,\n",
       "             'find': 230,\n",
       "             'going': 231,\n",
       "             'look': 232,\n",
       "             'asked': 233,\n",
       "             'later': 234,\n",
       "             'knew': 235,\n",
       "             'point': 236,\n",
       "             'next': 237,\n",
       "             'program': 238,\n",
       "             'city': 239,\n",
       "             'business': 240,\n",
       "             'group': 241,\n",
       "             'give': 242,\n",
       "             'toward': 243,\n",
       "             'young': 244,\n",
       "             'let': 245,\n",
       "             'days': 246,\n",
       "             'room': 247,\n",
       "             'president': 248,\n",
       "             'side': 249,\n",
       "             'social': 250,\n",
       "             'present': 251,\n",
       "             'given': 252,\n",
       "             'several': 253,\n",
       "             'order': 254,\n",
       "             'national': 255,\n",
       "             'possible': 256,\n",
       "             'rather': 257,\n",
       "             'second': 258,\n",
       "             'face': 259,\n",
       "             'per': 260,\n",
       "             'among': 261,\n",
       "             'form': 262,\n",
       "             'often': 263,\n",
       "             'important': 264,\n",
       "             'things': 265,\n",
       "             'looked': 266,\n",
       "             'early': 267,\n",
       "             'white': 268,\n",
       "             'john': 269,\n",
       "             'case': 270,\n",
       "             'large': 271,\n",
       "             'four': 272,\n",
       "             'need': 273,\n",
       "             'big': 274,\n",
       "             'become': 275,\n",
       "             'within': 276,\n",
       "             'felt': 277,\n",
       "             'children': 278,\n",
       "             'along': 279,\n",
       "             'saw': 280,\n",
       "             'best': 281,\n",
       "             'church': 282,\n",
       "             'ever': 283,\n",
       "             'least': 284,\n",
       "             'power': 285,\n",
       "             'development': 286,\n",
       "             'seemed': 287,\n",
       "             'thing': 288,\n",
       "             'light': 289,\n",
       "             'family': 290,\n",
       "             'interest': 291,\n",
       "             'want': 292,\n",
       "             'members': 293,\n",
       "             'mind': 294,\n",
       "             'area': 295,\n",
       "             'country': 296,\n",
       "             'others': 297,\n",
       "             'although': 298,\n",
       "             'turned': 299,\n",
       "             'done': 300,\n",
       "             'open': 301,\n",
       "             \"'\": 302,\n",
       "             'god': 303,\n",
       "             'service': 304,\n",
       "             'problem': 305,\n",
       "             'certain': 306,\n",
       "             'kind': 307,\n",
       "             'different': 308,\n",
       "             'thus': 309,\n",
       "             'began': 310,\n",
       "             'door': 311,\n",
       "             'help': 312,\n",
       "             'sense': 313,\n",
       "             'means': 314,\n",
       "             'whole': 315,\n",
       "             'matter': 316,\n",
       "             'perhaps': 317,\n",
       "             'itself': 318,\n",
       "             'york': 319,\n",
       "             \"it's\": 320,\n",
       "             'times': 321,\n",
       "             'law': 322,\n",
       "             'human': 323,\n",
       "             'line': 324,\n",
       "             'above': 325,\n",
       "             'name': 326,\n",
       "             'example': 327,\n",
       "             'action': 328,\n",
       "             'company': 329,\n",
       "             'hands': 330,\n",
       "             'local': 331,\n",
       "             'show': 332,\n",
       "             '3': 333,\n",
       "             'whether': 334,\n",
       "             'five': 335,\n",
       "             'history': 336,\n",
       "             'gave': 337,\n",
       "             'today': 338,\n",
       "             'either': 339,\n",
       "             'act': 340,\n",
       "             'feet': 341,\n",
       "             'across': 342,\n",
       "             'taken': 343,\n",
       "             'past': 344,\n",
       "             'quite': 345,\n",
       "             'anything': 346,\n",
       "             'seen': 347,\n",
       "             'having': 348,\n",
       "             'death': 349,\n",
       "             'experience': 350,\n",
       "             'body': 351,\n",
       "             'week': 352,\n",
       "             'half': 353,\n",
       "             'really': 354,\n",
       "             'word': 355,\n",
       "             'field': 356,\n",
       "             'car': 357,\n",
       "             'words': 358,\n",
       "             'already': 359,\n",
       "             'themselves': 360,\n",
       "             \"i'm\": 361,\n",
       "             'information': 362,\n",
       "             'tell': 363,\n",
       "             'shall': 364,\n",
       "             'together': 365,\n",
       "             'college': 366,\n",
       "             'money': 367,\n",
       "             'period': 368,\n",
       "             'held': 369,\n",
       "             'keep': 370,\n",
       "             'sure': 371,\n",
       "             'probably': 372,\n",
       "             'free': 373,\n",
       "             'seems': 374,\n",
       "             'political': 375,\n",
       "             'real': 376,\n",
       "             'cannot': 377,\n",
       "             'behind': 378,\n",
       "             'question': 379,\n",
       "             'air': 380,\n",
       "             'office': 381,\n",
       "             'making': 382,\n",
       "             'brought': 383,\n",
       "             'miss': 384,\n",
       "             'whose': 385,\n",
       "             'special': 386,\n",
       "             'major': 387,\n",
       "             'heard': 388,\n",
       "             'problems': 389,\n",
       "             'federal': 390,\n",
       "             'became': 391,\n",
       "             'study': 392,\n",
       "             'ago': 393,\n",
       "             'moment': 394,\n",
       "             'available': 395,\n",
       "             'known': 396,\n",
       "             'result': 397,\n",
       "             'street': 398,\n",
       "             'economic': 399,\n",
       "             'boy': 400,\n",
       "             'position': 401,\n",
       "             'reason': 402,\n",
       "             'change': 403,\n",
       "             'south': 404,\n",
       "             'board': 405,\n",
       "             'individual': 406,\n",
       "             'job': 407,\n",
       "             'am': 408,\n",
       "             'society': 409,\n",
       "             'areas': 410,\n",
       "             'west': 411,\n",
       "             'close': 412,\n",
       "             'turn': 413,\n",
       "             'community': 414,\n",
       "             'true': 415,\n",
       "             'love': 416,\n",
       "             'court': 417,\n",
       "             'force': 418,\n",
       "             'full': 419,\n",
       "             'cost': 420,\n",
       "             'seem': 421,\n",
       "             'wife': 422,\n",
       "             'future': 423,\n",
       "             'age': 424,\n",
       "             'wanted': 425,\n",
       "             'voice': 426,\n",
       "             'department': 427,\n",
       "             'center': 428,\n",
       "             'woman': 429,\n",
       "             'control': 430,\n",
       "             'common': 431,\n",
       "             'policy': 432,\n",
       "             'necessary': 433,\n",
       "             'following': 434,\n",
       "             'front': 435,\n",
       "             'sometimes': 436,\n",
       "             'six': 437,\n",
       "             'girl': 438,\n",
       "             'clear': 439,\n",
       "             'further': 440,\n",
       "             'land': 441,\n",
       "             'provide': 442,\n",
       "             'feel': 443,\n",
       "             'party': 444,\n",
       "             'able': 445,\n",
       "             'mother': 446,\n",
       "             'music': 447,\n",
       "             'education': 448,\n",
       "             'university': 449,\n",
       "             'child': 450,\n",
       "             'effect': 451,\n",
       "             'students': 452,\n",
       "             'level': 453,\n",
       "             'run': 454,\n",
       "             'stood': 455,\n",
       "             'military': 456,\n",
       "             'town': 457,\n",
       "             'short': 458,\n",
       "             'morning': 459,\n",
       "             'total': 460,\n",
       "             'outside': 461,\n",
       "             'rate': 462,\n",
       "             'figure': 463,\n",
       "             'art': 464,\n",
       "             'century': 465,\n",
       "             'class': 466,\n",
       "             'washington': 467,\n",
       "             '4': 468,\n",
       "             'north': 469,\n",
       "             'usually': 470,\n",
       "             'plan': 471,\n",
       "             'leave': 472,\n",
       "             'therefore': 473,\n",
       "             'evidence': 474,\n",
       "             'top': 475,\n",
       "             'million': 476,\n",
       "             'sound': 477,\n",
       "             'black': 478,\n",
       "             'strong': 479,\n",
       "             'hard': 480,\n",
       "             'tax': 481,\n",
       "             'various': 482,\n",
       "             'says': 483,\n",
       "             'believe': 484,\n",
       "             'type': 485,\n",
       "             'value': 486,\n",
       "             'play': 487,\n",
       "             'surface': 488,\n",
       "             'soon': 489,\n",
       "             'mean': 490,\n",
       "             'near': 491,\n",
       "             'lines': 492,\n",
       "             'table': 493,\n",
       "             'peace': 494,\n",
       "             'modern': 495,\n",
       "             'road': 496,\n",
       "             'red': 497,\n",
       "             'book': 498,\n",
       "             'personal': 499,\n",
       "             'process': 500,\n",
       "             'situation': 501,\n",
       "             'minutes': 502,\n",
       "             'increase': 503,\n",
       "             'schools': 504,\n",
       "             'idea': 505,\n",
       "             'english': 506,\n",
       "             'alone': 507,\n",
       "             'women': 508,\n",
       "             'gone': 509,\n",
       "             'nor': 510,\n",
       "             'living': 511,\n",
       "             'america': 512,\n",
       "             'started': 513,\n",
       "             'longer': 514,\n",
       "             'dr.': 515,\n",
       "             'cut': 516,\n",
       "             'finally': 517,\n",
       "             'secretary': 518,\n",
       "             'nature': 519,\n",
       "             'private': 520,\n",
       "             'third': 521,\n",
       "             'months': 522,\n",
       "             'section': 523,\n",
       "             'greater': 524,\n",
       "             'call': 525,\n",
       "             'fire': 526,\n",
       "             'expected': 527,\n",
       "             'needed': 528,\n",
       "             \"that's\": 529,\n",
       "             'kept': 530,\n",
       "             'ground': 531,\n",
       "             'view': 532,\n",
       "             'values': 533,\n",
       "             'everything': 534,\n",
       "             'pressure': 535,\n",
       "             'dark': 536,\n",
       "             'basis': 537,\n",
       "             'space': 538,\n",
       "             'east': 539,\n",
       "             'father': 540,\n",
       "             'required': 541,\n",
       "             'union': 542,\n",
       "             'spirit': 543,\n",
       "             'complete': 544,\n",
       "             'except': 545,\n",
       "             'wrote': 546,\n",
       "             \"i'll\": 547,\n",
       "             'moved': 548,\n",
       "             'support': 549,\n",
       "             'return': 550,\n",
       "             'conditions': 551,\n",
       "             'recent': 552,\n",
       "             'attention': 553,\n",
       "             'late': 554,\n",
       "             'particular': 555,\n",
       "             'live': 556,\n",
       "             'hope': 557,\n",
       "             'costs': 558,\n",
       "             'else': 559,\n",
       "             'brown': 560,\n",
       "             'taking': 561,\n",
       "             \"couldn't\": 562,\n",
       "             'forces': 563,\n",
       "             'nations': 564,\n",
       "             'beyond': 565,\n",
       "             'stage': 566,\n",
       "             'read': 567,\n",
       "             'report': 568,\n",
       "             'coming': 569,\n",
       "             'hours': 570,\n",
       "             'person': 571,\n",
       "             'inside': 572,\n",
       "             'dead': 573,\n",
       "             'material': 574,\n",
       "             'instead': 575,\n",
       "             'lost': 576,\n",
       "             'heart': 577,\n",
       "             'looking': 578,\n",
       "             'low': 579,\n",
       "             'miles': 580,\n",
       "             'data': 581,\n",
       "             'added': 582,\n",
       "             'pay': 583,\n",
       "             'amount': 584,\n",
       "             'followed': 585,\n",
       "             'feeling': 586,\n",
       "             '1960': 587,\n",
       "             'single': 588,\n",
       "             'makes': 589,\n",
       "             'research': 590,\n",
       "             'including': 591,\n",
       "             'basic': 592,\n",
       "             'hundred': 593,\n",
       "             'move': 594,\n",
       "             'industry': 595,\n",
       "             'cold': 596,\n",
       "             'simply': 597,\n",
       "             'developed': 598,\n",
       "             'tried': 599,\n",
       "             'hold': 600,\n",
       "             \"can't\": 601,\n",
       "             'reached': 602,\n",
       "             'committee': 603,\n",
       "             'island': 604,\n",
       "             'defense': 605,\n",
       "             'equipment': 606,\n",
       "             'actually': 607,\n",
       "             'shown': 608,\n",
       "             'son': 609,\n",
       "             'central': 610,\n",
       "             'religious': 611,\n",
       "             'river': 612,\n",
       "             'getting': 613,\n",
       "             'st.': 614,\n",
       "             'beginning': 615,\n",
       "             'sort': 616,\n",
       "             'ten': 617,\n",
       "             'received': 618,\n",
       "             '&': 619,\n",
       "             'doing': 620,\n",
       "             'terms': 621,\n",
       "             'trying': 622,\n",
       "             'rest': 623,\n",
       "             'medical': 624,\n",
       "             'u.s.': 625,\n",
       "             'care': 626,\n",
       "             'especially': 627,\n",
       "             'friends': 628,\n",
       "             'picture': 629,\n",
       "             'indeed': 630,\n",
       "             'administration': 631,\n",
       "             'fine': 632,\n",
       "             'subject': 633,\n",
       "             'difficult': 634,\n",
       "             'building': 635,\n",
       "             'higher': 636,\n",
       "             'wall': 637,\n",
       "             'simple': 638,\n",
       "             'meeting': 639,\n",
       "             'walked': 640,\n",
       "             'floor': 641,\n",
       "             'foreign': 642,\n",
       "             'bring': 643,\n",
       "             'similar': 644,\n",
       "             'passed': 645,\n",
       "             'range': 646,\n",
       "             'paper': 647,\n",
       "             'property': 648,\n",
       "             'natural': 649,\n",
       "             'final': 650,\n",
       "             'training': 651,\n",
       "             'county': 652,\n",
       "             'police': 653,\n",
       "             'cent': 654,\n",
       "             'international': 655,\n",
       "             'growth': 656,\n",
       "             'market': 657,\n",
       "             \"wasn't\": 658,\n",
       "             'talk': 659,\n",
       "             'start': 660,\n",
       "             'england': 661,\n",
       "             'written': 662,\n",
       "             'hear': 663,\n",
       "             'suddenly': 664,\n",
       "             'story': 665,\n",
       "             'issue': 666,\n",
       "             'congress': 667,\n",
       "             'needs': 668,\n",
       "             '10': 669,\n",
       "             'answer': 670,\n",
       "             'hall': 671,\n",
       "             'likely': 672,\n",
       "             'working': 673,\n",
       "             'countries': 674,\n",
       "             'considered': 675,\n",
       "             \"you're\": 676,\n",
       "             'earth': 677,\n",
       "             'sat': 678,\n",
       "             'purpose': 679,\n",
       "             'meet': 680,\n",
       "             'labor': 681,\n",
       "             'results': 682,\n",
       "             'entire': 683,\n",
       "             'happened': 684,\n",
       "             'william': 685,\n",
       "             'cases': 686,\n",
       "             'stand': 687,\n",
       "             'difference': 688,\n",
       "             'production': 689,\n",
       "             'hair': 690,\n",
       "             'involved': 691,\n",
       "             'fall': 692,\n",
       "             'stock': 693,\n",
       "             'food': 694,\n",
       "             'earlier': 695,\n",
       "             'increased': 696,\n",
       "             'whom': 697,\n",
       "             'particularly': 698,\n",
       "             'paid': 699,\n",
       "             'sent': 700,\n",
       "             'effort': 701,\n",
       "             'knowledge': 702,\n",
       "             'hour': 703,\n",
       "             'letter': 704,\n",
       "             'club': 705,\n",
       "             'using': 706,\n",
       "             'below': 707,\n",
       "             'thinking': 708,\n",
       "             'yes': 709,\n",
       "             'christian': 710,\n",
       "             'blue': 711,\n",
       "             'ready': 712,\n",
       "             'bill': 713,\n",
       "             'deal': 714,\n",
       "             'points': 715,\n",
       "             'trade': 716,\n",
       "             'certainly': 717,\n",
       "             'ideas': 718,\n",
       "             'industrial': 719,\n",
       "             'square': 720,\n",
       "             'boys': 721,\n",
       "             'methods': 722,\n",
       "             'addition': 723,\n",
       "             'method': 724,\n",
       "             'bad': 725,\n",
       "             'due': 726,\n",
       "             '5': 727,\n",
       "             'girls': 728,\n",
       "             'moral': 729,\n",
       "             'decided': 730,\n",
       "             'reading': 731,\n",
       "             'statement': 732,\n",
       "             'weeks': 733,\n",
       "             'neither': 734,\n",
       "             'nearly': 735,\n",
       "             'directly': 736,\n",
       "             'showed': 737,\n",
       "             'throughout': 738,\n",
       "             'according': 739,\n",
       "             'questions': 740,\n",
       "             'color': 741,\n",
       "             'kennedy': 742,\n",
       "             'anyone': 743,\n",
       "             'try': 744,\n",
       "             'services': 745,\n",
       "             'programs': 746,\n",
       "             'nation': 747,\n",
       "             'lay': 748,\n",
       "             'french': 749,\n",
       "             'size': 750,\n",
       "             'remember': 751,\n",
       "             'physical': 752,\n",
       "             'record': 753,\n",
       "             'member': 754,\n",
       "             'comes': 755,\n",
       "             'understand': 756,\n",
       "             'southern': 757,\n",
       "             'western': 758,\n",
       "             'strength': 759,\n",
       "             'population': 760,\n",
       "             'normal': 761,\n",
       "             'merely': 762,\n",
       "             'district': 763,\n",
       "             'volume': 764,\n",
       "             'concerned': 765,\n",
       "             'appeared': 766,\n",
       "             'temperature': 767,\n",
       "             '1961': 768,\n",
       "             'aid': 769,\n",
       "             'trouble': 770,\n",
       "             'trial': 771,\n",
       "             'summer': 772,\n",
       "             'direction': 773,\n",
       "             'ran': 774,\n",
       "             'sales': 775,\n",
       "             'list': 776,\n",
       "             'continued': 777,\n",
       "             'friend': 778,\n",
       "             'evening': 779,\n",
       "             'maybe': 780,\n",
       "             'literature': 781,\n",
       "             'generally': 782,\n",
       "             'association': 783,\n",
       "             'provided': 784,\n",
       "             'led': 785,\n",
       "             'army': 786,\n",
       "             'met': 787,\n",
       "             'influence': 788,\n",
       "             'opened': 789,\n",
       "             'former': 790,\n",
       "             'science': 791,\n",
       "             'student': 792,\n",
       "             'step': 793,\n",
       "             'changes': 794,\n",
       "             'chance': 795,\n",
       "             'husband': 796,\n",
       "             'hot': 797,\n",
       "             'series': 798,\n",
       "             'average': 799,\n",
       "             'works': 800,\n",
       "             'month': 801,\n",
       "             'cause': 802,\n",
       "             'effective': 803,\n",
       "             'george': 804,\n",
       "             'planning': 805,\n",
       "             'systems': 806,\n",
       "             \"wouldn't\": 807,\n",
       "             'direct': 808,\n",
       "             'soviet': 809,\n",
       "             'stopped': 810,\n",
       "             'wrong': 811,\n",
       "             'lead': 812,\n",
       "             'myself': 813,\n",
       "             'piece': 814,\n",
       "             'theory': 815,\n",
       "             'ask': 816,\n",
       "             'worked': 817,\n",
       "             'freedom': 818,\n",
       "             'organization': 819,\n",
       "             'clearly': 820,\n",
       "             'movement': 821,\n",
       "             'ways': 822,\n",
       "             'press': 823,\n",
       "             'somewhat': 824,\n",
       "             'spring': 825,\n",
       "             'efforts': 826,\n",
       "             'consider': 827,\n",
       "             'meaning': 828,\n",
       "             'bed': 829,\n",
       "             'fear': 830,\n",
       "             'lot': 831,\n",
       "             'treatment': 832,\n",
       "             'beautiful': 833,\n",
       "             'note': 834,\n",
       "             'forms': 835,\n",
       "             'placed': 836,\n",
       "             'hotel': 837,\n",
       "             'truth': 838,\n",
       "             'apparently': 839,\n",
       "             'degree': 840,\n",
       "             'groups': 841,\n",
       "             \"he's\": 842,\n",
       "             'plant': 843,\n",
       "             'carried': 844,\n",
       "             'wide': 845,\n",
       "             \"i've\": 846,\n",
       "             'respect': 847,\n",
       "             \"man's\": 848,\n",
       "             'herself': 849,\n",
       "             'numbers': 850,\n",
       "             'manner': 851,\n",
       "             'reaction': 852,\n",
       "             'easy': 853,\n",
       "             'farm': 854,\n",
       "             'immediately': 855,\n",
       "             'running': 856,\n",
       "             'approach': 857,\n",
       "             'game': 858,\n",
       "             'recently': 859,\n",
       "             'larger': 860,\n",
       "             'lower': 861,\n",
       "             'charge': 862,\n",
       "             'couple': 863,\n",
       "             'de': 864,\n",
       "             'daily': 865,\n",
       "             'eye': 866,\n",
       "             'performance': 867,\n",
       "             'feed': 868,\n",
       "             'oh': 869,\n",
       "             'march': 870,\n",
       "             'persons': 871,\n",
       "             'understanding': 872,\n",
       "             'arms': 873,\n",
       "             'opportunity': 874,\n",
       "             'c': 875,\n",
       "             'blood': 876,\n",
       "             'additional': 877,\n",
       "             'j.': 878,\n",
       "             'technical': 879,\n",
       "             'fiscal': 880,\n",
       "             'radio': 881,\n",
       "             'described': 882,\n",
       "             'stop': 883,\n",
       "             'progress': 884,\n",
       "             'steps': 885,\n",
       "             'test': 886,\n",
       "             'chief': 887,\n",
       "             'reported': 888,\n",
       "             'served': 889,\n",
       "             'based': 890,\n",
       "             'main': 891,\n",
       "             'determined': 892,\n",
       "             'image': 893,\n",
       "             'decision': 894,\n",
       "             'window': 895,\n",
       "             'religion': 896,\n",
       "             'aj': 897,\n",
       "             'gun': 898,\n",
       "             'responsibility': 899,\n",
       "             'middle': 900,\n",
       "             'europe': 901,\n",
       "             'british': 902,\n",
       "             'character': 903,\n",
       "             'learned': 904,\n",
       "             'horse': 905,\n",
       "             'writing': 906,\n",
       "             'appear': 907,\n",
       "             's.': 908,\n",
       "             'account': 909,\n",
       "             'ones': 910,\n",
       "             'serious': 911,\n",
       "             'activity': 912,\n",
       "             'types': 913,\n",
       "             'green': 914,\n",
       "             'length': 915,\n",
       "             'lived': 916,\n",
       "             'audience': 917,\n",
       "             'letters': 918,\n",
       "             'returned': 919,\n",
       "             'obtained': 920,\n",
       "             'nuclear': 921,\n",
       "             'specific': 922,\n",
       "             'corner': 923,\n",
       "             'forward': 924,\n",
       "             'activities': 925,\n",
       "             'slowly': 926,\n",
       "             'doubt': 927,\n",
       "             '6': 928,\n",
       "             'justice': 929,\n",
       "             'moving': 930,\n",
       "             'latter': 931,\n",
       "             'gives': 932,\n",
       "             'straight': 933,\n",
       "             'hit': 934,\n",
       "             'plane': 935,\n",
       "             'quality': 936,\n",
       "             'design': 937,\n",
       "             'obviously': 938,\n",
       "             'operation': 939,\n",
       "             'plans': 940,\n",
       "             'shot': 941,\n",
       "             'seven': 942,\n",
       "             'a.': 943,\n",
       "             'choice': 944,\n",
       "             'poor': 945,\n",
       "             'staff': 946,\n",
       "             'function': 947,\n",
       "             'figures': 948,\n",
       "             'parts': 949,\n",
       "             'stay': 950,\n",
       "             'saying': 951,\n",
       "             'include': 952,\n",
       "             '15': 953,\n",
       "             'born': 954,\n",
       "             'pattern': 955,\n",
       "             '30': 956,\n",
       "             'cars': 957,\n",
       "             'whatever': 958,\n",
       "             'sun': 959,\n",
       "             'faith': 960,\n",
       "             'pool': 961,\n",
       "             'hospital': 962,\n",
       "             'corps': 963,\n",
       "             'wish': 964,\n",
       "             'lack': 965,\n",
       "             'completely': 966,\n",
       "             'heavy': 967,\n",
       "             'waiting': 968,\n",
       "             'speak': 969,\n",
       "             'ball': 970,\n",
       "             'standard': 971,\n",
       "             'extent': 972,\n",
       "             'visit': 973,\n",
       "             'democratic': 974,\n",
       "             'firm': 975,\n",
       "             'income': 976,\n",
       "             'ahead': 977,\n",
       "             'deep': 978,\n",
       "             \"there's\": 979,\n",
       "             'language': 980,\n",
       "             'principle': 981,\n",
       "             'none': 982,\n",
       "             'price': 983,\n",
       "             'designed': 984,\n",
       "             'indicated': 985,\n",
       "             'analysis': 986,\n",
       "             'distance': 987,\n",
       "             'expect': 988,\n",
       "             'established': 989,\n",
       "             'products': 990,\n",
       "             'effects': 991,\n",
       "             'growing': 992,\n",
       "             'importance': 993,\n",
       "             'continue': 994,\n",
       "             'serve': 995,\n",
       "             'determine': 996,\n",
       "             'cities': 997,\n",
       "             'elements': 998,\n",
       "             'negro': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id # словарь из слов, упорядоченных по возрастанию их использование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCmGbwpP8aHu"
   },
   "source": [
    "Преобразуем слова и тэги в  fixed-size matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X7kx6jWn8aHu"
   },
   "outputs": [],
   "source": [
    "def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n",
    "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,lines))\n",
    "    matrix = np.empty([len(lines), max_len],dtype)\n",
    "    matrix.fill(pad)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
    "        matrix[i,:len(line_ix)] = line_ix\n",
    "\n",
    "    return matrix.T if time_major else matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BCaE-i5u8aHu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ids:\n",
      "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
      "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
      "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
      "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
      "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
      "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
      " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
      "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "Tag ids:\n",
      "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
      "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
      "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
      "   6  3  2 13  7]\n",
      " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
    "\n",
    "print(\"Word ids:\")\n",
    "print(to_matrix(batch_words, word_to_id))\n",
    "print(\"Tag ids:\")\n",
    "print(to_matrix(batch_tags, tag_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "_oK_i5Xa8aHv"
   },
   "source": [
    "### Build model\n",
    "\n",
    "Unlike our previous lab, this time we'll focus on a high-level keras interface to recurrent neural networks. It is as simple as you can get with RNN, allbeit somewhat constraining for complex tasks like seq2seq.\n",
    "\n",
    "By default, all keras RNNs apply to a whole sequence of inputs and produce a sequence of hidden states `(return_sequences=True` or just the last hidden state `(return_sequences=False)`. All the recurrence is happening under the hood.\n",
    "\n",
    "At the top of our model we need to apply a Dense layer to each time-step independently. As of now, by default keras.layers.Dense would apply once to all time-steps concatenated. We use __keras.layers.TimeDistributed__ to modify Dense layer so that it would apply across both batch and time axes.\n",
    "\n",
    "В отличие от нашей предыдущей работы, на этот раз мы сосредоточимся на высокоуровневом интерфейсе keras для рекуррентных нейронных сетей. Это настолько просто, насколько вы можете получить с помощью RNN, хотя и несколько ограничено для сложных задач, таких как seq2seq.\n",
    "\n",
    "По умолчанию все RNN keras применяются ко всей последовательности входных данных и создают последовательность скрытых состояний (return_sequences=True или только последнее скрытое состояние (return_sequences=False). Все повторения происходят под капотом.\n",
    "\n",
    "В верхней части нашей модели нам нужно применить Dense слой к каждому временному шагу независимо. На данный момент keras.layers.Dense по умолчанию применяется один раз ко всем объединенным временным шагам. Мы используем  __keras.layers.TimeDistributed__ для изменения Dense слоя, чтобы он применялся как к пакетной, так и к временной осям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OQeb8d5j8aHv"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([None],dtype='int32'))\n",
    "model.add(L.Embedding(len(all_words),50))\n",
    "model.add(L.SimpleRNN(64,return_sequences=True))\n",
    "\n",
    "#add top layer that predicts tag probabilities\n",
    "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQbJqM2n8aHv"
   },
   "source": [
    "__Training:__ in this case we don't want to prepare the whole training dataset in advance. The main cause is that the length of every batch depends on the maximum sentence length within the batch. This leaves us two options: use custom training code as in previous seminar or use generators.\n",
    "\n",
    "Keras models have a __`model.fit_generator`__ method that accepts a python generator yielding one batch at a time. But first we need to implement such generator:\n",
    "\n",
    "\n",
    "Обучение: в этом случае мы не хотим заранее готовить весь набор обучающих данных. Основная причина в том, что длина каждого пакета зависит от максимальной длины предложения в пакете. Это оставляет нам два варианта: использовать собственный обучающий код, как на предыдущем семинаре, или использовать генераторы.\n",
    "\n",
    "В моделях Keras есть метод __`model.fit_generator`__, который принимает генератор Python, выдающий по одному пакету за раз. Но сначала нам нужно реализовать такой генератор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kpeMsDi18aHw"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
    "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
    "    \n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(len(sentences)))\n",
    "        for start in range(0,len(indices)-1,batch_size):\n",
    "            batch_indices = indices[start:start+batch_size]\n",
    "            batch_words,batch_tags = [],[]\n",
    "            for sent in sentences[batch_indices]:\n",
    "                words,tags = zip(*sent)\n",
    "                batch_words.append(words)\n",
    "                batch_tags.append(tags)\n",
    "\n",
    "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
    "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
    "\n",
    "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
    "            yield batch_words,batch_tags_1hot\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYoR9vgn8aHw"
   },
   "source": [
    "еще одна вещь, которая нам нужна, — это измерение производительности модели. Сложность заключается не в том, чтобы считать точность после окончания предложения (при заполнении), а в том, чтобы убедиться, что мы считаем все данные проверки ровно один раз.\n",
    "\n",
    "Хотя нет ничего невозможного в том, чтобы убедить Keras сделать все это, мы можем также написать собственный обратный вызов, который сделает это. Обратные вызовы Keras позволяют вам написать собственный код, который будет запускаться один раз в каждую эпоху или каждый мини-пакет. Мы определим его через LambdaCallback\n",
    "__Callbacks:__ Another thing we need is to measure model performance. The tricky part is not to count accuracy after sentence ends (on padding) and making sure we count all the validation data exactly once.\n",
    "\n",
    "While it isn't impossible to persuade Keras to do all of that, we may as well write our own callback that does that.\n",
    "Keras callbacks allow you to write a custom code to be ran once every epoch or every minibatch. We'll define one via LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CC8woNtV8aHx"
   },
   "outputs": [],
   "source": [
    "def compute_test_accuracy(model):\n",
    "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
    "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
    "\n",
    "    #predict tag probabilities of shape [batch,time,n_tags]\n",
    "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
    "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
    "\n",
    "    #compute accurary excluding padding\n",
    "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
    "    denominator = np.sum(test_words != 0)\n",
    "    return float(numerator)/denominator\n",
    "\n",
    "\n",
    "class EvaluateAccuracy(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\nMeasuring validation accuracy...\")\n",
    "        acc = compute_test_accuracy(self.model)\n",
    "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
    "        sys.stdout.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5eJGEWu58aHx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_19284/3694479188.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.2670\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 13ms/step\n",
      "\n",
      "Validation accuracy: 0.94040\n",
      "\n",
      "1343/1343 [==============================] - 28s 19ms/step - loss: 0.2667\n",
      "Epoch 2/5\n",
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.0585\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 5s 12ms/step\n",
      "\n",
      "Validation accuracy: 0.94404\n",
      "\n",
      "1343/1343 [==============================] - 24s 18ms/step - loss: 0.0585\n",
      "Epoch 3/5\n",
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.0515\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 5s 12ms/step\n",
      "\n",
      "Validation accuracy: 0.94517\n",
      "\n",
      "1343/1343 [==============================] - 26s 20ms/step - loss: 0.0515\n",
      "Epoch 4/5\n",
      "1341/1343 [============================>.] - ETA: 0s - loss: 0.0474\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 5s 12ms/step\n",
      "\n",
      "Validation accuracy: 0.94595\n",
      "\n",
      "1343/1343 [==============================] - 27s 20ms/step - loss: 0.0474\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0428\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 7s 15ms/step\n",
      "\n",
      "Validation accuracy: 0.94421\n",
      "\n",
      "1343/1343 [==============================] - 31s 23ms/step - loss: 0.0428\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "history = model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.2667122781276703, 0.05853678658604622, 0.05151652172207832, 0.04735688865184784, 0.04276196286082268]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2f0874f3cd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history)\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTN7C34V8aHy"
   },
   "source": [
    "Measure final accuracy on the whole test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tHgxnYB68aHy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 5s 12ms/step\n",
      "Final accuracy: 0.94421\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"Final accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc>0.94, \"Keras has gone on a rampage again, please contact course staff.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L5Prr4I8aHy"
   },
   "source": [
    "### Going bidirectional\n",
    "\n",
    "Since we're analyzing a full sequence, it's legal for us to look into future data.\n",
    "\n",
    "A simple way to achieve that is to go both directions at once, making a __bidirectional RNN__.\n",
    "\n",
    "In Keras you can achieve that both manually (using two LSTMs and Concatenate) and by using __`keras.layers.Bidirectional`__. \n",
    "\n",
    "This one works just as `TimeDistributed` we saw before: you wrap it around a recurrent layer (SimpleRNN now and LSTM/GRU later) and it actually creates two layers under the hood.\n",
    "\n",
    "Your first task is to use such a layer our POS-tagger.\n",
    "\n",
    "Поскольку мы анализируем полную последовательность, мы можем смотреть на будущие данные.\n",
    "\n",
    "Простой способ добиться этого — двигаться в обоих направлениях одновременно, создавая двунаправленную RNN.\n",
    "\n",
    "В Keras вы можете добиться этого как вручную (используя два LSTM и Concatenate), так и используя keras.layers.Bidirectional.\n",
    "\n",
    "Он работает так же, как TimeDistributed, который мы видели раньше: вы оборачиваете его вокруг рекуррентного слоя (сейчас SimpleRNN, а позже LSTM/GRU), и он фактически создает два слоя под капотом.\n",
    "\n",
    "Ваша первая задача — использовать такой слой, как наш POS-тегер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xWfCrbh-8aHy"
   },
   "outputs": [],
   "source": [
    "# Создадим модель с  bidirectional SimpleRNN\n",
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([None],dtype='int32'))\n",
    "model.add(L.Embedding(len(all_words),50))\n",
    "model.add(L.Bidirectional(L.SimpleRNN(64, return_sequences=True)))\n",
    "# add top layer that predicts tag probabilities\n",
    "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ort64W348aHz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_19284/2198750851.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.2066\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 9s 20ms/step\n",
      "\n",
      "Validation accuracy: 0.95579\n",
      "\n",
      "1343/1343 [==============================] - 43s 31ms/step - loss: 0.2065\n",
      "Epoch 2/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0428\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 9s 21ms/step\n",
      "\n",
      "Validation accuracy: 0.96049\n",
      "\n",
      "1343/1343 [==============================] - 44s 33ms/step - loss: 0.0428\n",
      "Epoch 3/5\n",
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.0350\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 10s 22ms/step\n",
      "\n",
      "Validation accuracy: 0.96237\n",
      "\n",
      "1343/1343 [==============================] - 48s 36ms/step - loss: 0.0350\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0295\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 10s 21ms/step\n",
      "\n",
      "Validation accuracy: 0.96222\n",
      "\n",
      "1343/1343 [==============================] - 45s 33ms/step - loss: 0.0295\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 10s 23ms/step\n",
      "\n",
      "Validation accuracy: 0.96113\n",
      "\n",
      "1343/1343 [==============================] - 49s 37ms/step - loss: 0.0244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f0872b3760>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "iWHSkF648aHz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 10s 22ms/step\n",
      "\n",
      "Final accuracy: 0.96113\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW_nFppS8aH0"
   },
   "source": [
    "Task I: Structured loss functions (more bonus points) Структурированные функции потерь\n",
    "\n",
    "Since we're tagging the whole sequence at once, we might as well train our network to do so. Remember linear CRF from the lecture? You can also use it as a loss function for your RNN\n",
    "\n",
    "Поскольку мы помечаем всю последовательность сразу, мы могли бы также научить нашу сеть делать это. Помните линейную CRF из лекции? Вы также можете использовать его как функцию потерь для вашей RNN.\n",
    "\n",
    "  * Есть несколько способов сделать это, но мы рекомендуем начать с [Conditional Random Fields](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)\n",
    "  * You can plug CRF as a loss function and still train by backprop. There's even some neat tensorflow [implementation](https://www.tensorflow.org/addons/api_docs/python/tfa/layers/CRF) for you.\n",
    "  Вы можете подключить CRF как функцию потерь и по-прежнему тренироваться с помощью обратного распространения. \n",
    "  * Alternatively, you can condition your model on previous tags (make it autoregressive) and perform __beam search__ over that model.\n",
    "  \n",
    "Кроме того, вы можете обусловить свою модель предыдущими тегами (сделать ее авторегрессивной) и выполнить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TF1T00yr8RvM"
   },
   "outputs": [],
   "source": [
    "#Define a model that utilizes bidirectional SimpleRNN\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(L.InputLayer([None],dtype='int32'))\n",
    "model.add(L.Embedding(len(all_words),50))\n",
    "model.add(L.Bidirectional(L.GRU(128,return_sequences=True,activation='relu')))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Bidirectional(L.GRU(64,return_sequences=True,activation='relu')))\n",
    "model.add(L.Dropout(0.5))\n",
    "\n",
    "#add top layer that predicts tag probabilities\n",
    "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_19284/2696369520.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344/1343 [==============================] - ETA: 0s - loss: 0.1930\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 51s 114ms/step\n",
      "\n",
      "Validation accuracy: 0.95642\n",
      "\n",
      "1343/1343 [==============================] - 243s 177ms/step - loss: 0.1930\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0518\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 45s 101ms/step\n",
      "\n",
      "Validation accuracy: 0.96195\n",
      "\n",
      "1343/1343 [==============================] - 233s 173ms/step - loss: 0.0518\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0438\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 51s 113ms/step\n",
      "\n",
      "Validation accuracy: 0.96444\n",
      "\n",
      "1343/1343 [==============================] - 225s 167ms/step - loss: 0.0438\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0391\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 54s 122ms/step\n",
      "\n",
      "Validation accuracy: 0.96581\n",
      "\n",
      "1343/1343 [==============================] - 226s 168ms/step - loss: 0.0391\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0361\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 76s 170ms/step\n",
      "\n",
      "Validation accuracy: 0.96608\n",
      "\n",
      "1343/1343 [==============================] - 267s 199ms/step - loss: 0.0361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f087a96190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feel free to change anything here\n",
    "adam = keras.optimizers.Adam(clipnorm=1.2)\n",
    "model.compile(adam,'categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  1/167 [..............................] - ETA: 21s - loss: 0.0268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_19284/1797685126.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/167 [==============================] - ETA: 0s - loss: 0.0337\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 59s 131ms/step\n",
      "\n",
      "Validation accuracy: 0.96684\n",
      "\n",
      "167/167 [==============================] - 85s 505ms/step - loss: 0.0337\n",
      "Epoch 2/2\n",
      "168/167 [==============================] - ETA: 0s - loss: 0.0327\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 66s 147ms/step\n",
      "\n",
      "Validation accuracy: 0.96683\n",
      "\n",
      "167/167 [==============================] - 93s 555ms/step - loss: 0.0327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f0fbc7a250>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "model.fit_generator(generate_batches(train_data),len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 64s 144ms/step\n",
      "\n",
      "Final accuracy: 0.96683\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1y2vX9lOI1KaMyOJbGegKs5QwVrkBRso5",
     "timestamp": 1686510984268
    },
    {
     "file_id": "https://github.com/waytobehigh/nlp_course/blob/master/week05_structured/rnn_tagger.ipynb",
     "timestamp": 1617022812789
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
